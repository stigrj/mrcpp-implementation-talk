name: inverse
layout: true
class: center, middle, inverse
---
#MRCPP
##Data structures and algorithms

.author[Stig Rune Jensen]

.date[3 August 2016, Stony Brook, NY]

.footnote[Slides available on [GitHub](https://github.com/stigrj/mrcpp-implementation-talk)]

---

layout: false
.left-column[
## Technical stuff
]
.right-column[
- Hosted on GitHub

- Documentation on ReadTheDocs

- Configuration with (Auto)cmake

- Testing with Catch

- Number crunching with BLAS

- Parallelization with OpenMP
]

---
template: inverse
# Data structures
---

.left-column[
## Data structures
### - MWTree
]
.right-column[
- Functions and operators organized in tree structures

- Memory allocator keeps data localized

- MRA defines
  * Root scale (can be negative)
  * Number of root nodes
  * Type of MW basis (Legendre/Interpolating)
  * Order of MW basis (`\(1 \leq k \leq 40\)`)

```cpp
template<int D>
class MWTree {
    TreeAllocator<D> allocator;      // Memory allocator
    MultiResolutionAnalysis<D> MRA;  // World, MW basis

    std::vector<MWNode<D> *> roots;  // Root container
    std::vector<MWNode<D> *> leaves; // Leaf container

    double squareNorm;               // Squared L^2 norm
    std::vector<int> nodesAtDepth;   // Node counter
}
```
]

---

.left-column[
## Data structures
### - MWTree
### - MWNode
]
.right-column[
- NodeIndex defines
  * Length scale: `\(2^{-n}\)`
  * Translation: `\([l/2^{n},(l+1)/2^{n}]\)`

- Each node keeps __both__ scaling and wavelet coefficients

```cpp
template<int D>
class MWNode {
    NodeIndex<D> idx;           // Scale and translation

    MWTree<D> *tree;            // Tree it belongs to
    MWNode<D> *parent;          // Parent node
    MWNode<D> *children[2^D];   // Children nodes

    double squareNorm;          // Squared L^2 norm
    double componentNorms[2^D]; // Scaling/wavelet norms
    double *coefs;              // Scaling/wavelet coefs
}
```
]

---

.left-column[
## Data structures
### - MWTree
### - MWNode
]
.right-column[



<img src="images/adaptivity.jpg" style="width: 80%">
]

---

.left-column[
## Data structures
### - MWTree
### - MWNode
]
.right-column[
#### Representations

- MRA allows for fine-scale representation

  `$$ f^N = \sum_{l=0}^{2^N-1}\sum_{j=0}^{k} s_{jl}^N \phi_{jl}^N(x) $$`

- or multi-scale representation

  `$$ f^N = \sum_{j=0}^{k} s_{jl}^0 \phi_{jl}^0(x) +
  \sum_{n=0}^{N-1}\sum_{l=0}^{2^N-1}\sum_{j=0}^{k} w_{jl}^n \psi_{jl}^n(x) $$`

- We keep a __redundant__ representation of both scaling and wavelet
  coefficients on __all__ scales
]

---

.left-column[
## Data structures
### - MWTree
### - MWNode
]
.right-column[
#### Transformations

- We can go from a `\(V^n \oplus W^n\)` representation
  to a `\(V^{n+1}\)` representation using the MW transform

- We can go from a `\(V^{n+1}\)` representation to a function value
  representation using the CV transform (coefficient-value)

```cpp
MWNode<D> node;                     // V^{n} + W^{n}

node.mwTransform(Reconstruction);   // V^{n+1}
    
node.cvTransform(Forward);          // Function values
    
node.cvTransform(Backward);         // V^{n+1}
    
node.mwTransform(Compression);      // V^{n} + W^{n}
```
]

---

.left-column[
## Data structures
### - MWTree
### - MWNode
]
.right-column[
#### Transformations

- Often require nodes beyond the finest refinement level

- Information available by MW transform

- Corresponds to an oversampling of the function

- Possible strategies
  * perform MW transforms on the fly whenever needed
  * extend the tree with temporary nodes for later use

- GenNodes
  * generated by MW transform
  * only scaling coefs (wavelet coefs are zero)
  * kept until the particular operation is completed
]

---

.left-column[
## Data structures
### - MWTree
### - MWNode
]
.right-column[
#### Multiple dimensions

- Extenstion to 2D by tensor product

 `$$$
    V^n \otimes V^n
  $$$`

- Wavelet decomposition results in several wavelet spaces

 `$$$
    V^n \otimes V^n = 
    \Big(V^{n-1} \oplus W^{n-1}\Big) \otimes
    \Big(V^{n-1} \oplus W^{n-1}\Big) = 
    \Big(V^{n-1} \otimes V^{n-1}\Big) \oplus
    \Big(V^{n-1} \otimes W^{n-1}\Big) \oplus
    \Big(W^{n-1} \otimes V^{n-1}\Big) \oplus
    \Big(W^{n-1} \otimes W^{n-1}\Big)
  $$$`
]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Convolution operators
- General nD integral operator

  `$$ 
    \hat{T}f(\boldsymbol{x}) = 
    \int K(\boldsymbol{x},\boldsymbol{y})f(\boldsymbol{y}) d\boldsymbol{y}
   $$`

- Separable representation

  `$$
    K(\boldsymbol{x},\boldsymbol{y}) \approx 
    \tilde{K}(\boldsymbol{x},\boldsymbol{y}) =
    \sum_\kappa^M \alpha_\kappa \prod_{p=1}^d K_p^\kappa(x_p,y_p)
   $$`

- Find parameters such that

  `$$
    sup_y\left|\frac{K(\boldsymbol{x},\boldsymbol{y}) -
    \tilde{K}(\boldsymbol{x},\boldsymbol{y})}
    {K(\boldsymbol{x},\boldsymbol{y})}\right| \leq
    \epsilon
   $$`

- Decompose into a sum of products of 1D operators

- Reduce the complexity from `\(k^{2d}\)` to `\(Mdk^{d+1}\)`
]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Poisson operator
- The Poisson equation relates the electrostatic potential `\(V\)`
  to the charge density `\(\rho\)`
 
  `$$
    \nabla^2 V(\boldsymbol{x}) = -\rho(\boldsymbol{x})
   $$`

- Direct solution in integral form
  `$$
    V(\boldsymbol{x}) =
    \int P(\boldsymbol{x},\boldsymbol{y})\rho(\boldsymbol{y}) d\boldsymbol{y}
   $$`

- Poisson kernel

  `$$
    P(\boldsymbol{x},\boldsymbol{y}) = \frac{1}{4\pi\|\boldsymbol{x}-\boldsymbol{y}\|}
   $$`

- Numerical problems
  * Non-separable
  * Singularity at short range
  * Slow decay at long range
]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Poisson operator
- Poisson kernel separated in terms of Gaussians
  `$$
    P(\boldsymbol{x},\boldsymbol{y}) \approx
    \tilde{P}(\boldsymbol{x},\boldsymbol{y}) =
    \sum_\kappa^M \alpha_{\kappa} \prod_{p=1}^d e^{-\beta_{\kappa}(x_p-y_p)^2}
   $$`

- Expansion obtained from the relation

  `$$
    \frac{1}{r} = \frac{4}{\sqrt{\pi}}\int_0^\infty e^{-4r^2t^2} dt
   $$`

- Substitution: `\(t = log(1+e^u)-u\)`
  
  `$$
    \frac{1}{r} = \int_{-\infty}^{\infty} f_1(u) du
   $$`

- Substitution: `\(u = -sinh(w)\)`
  
  `$$
    \frac{1}{r} = \int_{-\infty}^{\infty} f_2(w) dw
   $$`

- Super-exponential decay for `\(w \rightarrow \pm \infty\)` 
]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Poisson operator
- Poisson kernel separated in terms of Gaussians

  `$$
    P(\boldsymbol{x},\boldsymbol{y}) \approx
    \tilde{P}(\boldsymbol{x},\boldsymbol{y}) =
    \sum_\kappa^M \alpha_{\kappa} \prod_{p=1}^d e^{-\beta_{\kappa}(x_p-y_p)^2}
   $$`

<img src="images/kernel_1.jpg" style="width: 80%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Poisson operator
- Poisson kernel separated in terms of Gaussians

  `$$
    P(\boldsymbol{x},\boldsymbol{y}) \approx
    \tilde{P}(\boldsymbol{x},\boldsymbol{y}) =
    \sum_\kappa^M \alpha_{\kappa} \prod_{p=1}^d e^{-\beta_{\kappa}(x_p-y_p)^2}
   $$`

<img src="images/kernel_2.jpg" style="width: 80%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Poisson operator
- Poisson kernel separated in terms of Gaussians

  `$$
    P(\boldsymbol{x},\boldsymbol{y}) \approx
    \tilde{P}(\boldsymbol{x},\boldsymbol{y}) =
    \sum_\kappa^M \alpha_{\kappa} \prod_{p=1}^d e^{-\beta_{\kappa}(x_p-y_p)^2}
   $$`

<img src="images/kernel_3.jpg" style="width: 80%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Poisson operator
- Poisson kernel separated in terms of Gaussians

  `$$
    P(\boldsymbol{x},\boldsymbol{y}) \approx
    \tilde{P}(\boldsymbol{x},\boldsymbol{y}) =
    \sum_\kappa^M \alpha_{\kappa} \prod_{p=1}^d e^{-\beta_{\kappa}(x_p-y_p)^2}
   $$`

<img src="images/kernel_4.jpg" style="width: 80%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Poisson operator
- Poisson kernel separated in terms of Gaussians

  `$$
    P(\boldsymbol{x},\boldsymbol{y}) \approx
    \tilde{P}(\boldsymbol{x},\boldsymbol{y}) =
    \sum_\kappa^M \alpha_{\kappa} \prod_{p=1}^d e^{-\beta_{\kappa}(x_p-y_p)^2}
   $$`

<img src="images/kernel_5.jpg" style="width: 80%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Poisson operator
- Poisson kernel separated in terms of Gaussians

  `$$
    P(\boldsymbol{x},\boldsymbol{y}) \approx
    \tilde{P}(\boldsymbol{x},\boldsymbol{y}) =
    \sum_\kappa^M \alpha_{\kappa} \prod_{p=1}^d e^{-\beta_{\kappa}(x_p-y_p)^2}
   $$`

<img src="images/kernel_6.jpg" style="width: 80%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Poisson operator
- Poisson kernel separated in terms of Gaussians

  `$$
    P(\boldsymbol{x},\boldsymbol{y}) \approx
    \tilde{P}(\boldsymbol{x},\boldsymbol{y}) =
    \sum_\kappa^M \alpha_{\kappa} \prod_{p=1}^d e^{-\beta_{\kappa}(x_p-y_p)^2}
   $$`

<img src="images/kernel_7.jpg" style="width: 80%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Poisson operator
- Poisson kernel separated in terms of Gaussians

  `$$
    P(\boldsymbol{x},\boldsymbol{y}) \approx
    \tilde{P}(\boldsymbol{x},\boldsymbol{y}) =
    \sum_\kappa^M \alpha_{\kappa} \prod_{p=1}^d e^{-\beta_{\kappa}(x_p-y_p)^2}
   $$`

- Solves numerical problems
  * Separates coordinates
  * Remove singularity
  * Separates length scales

- However
  * `\(M\)` convolution operators instead of one
]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Convolution operators
- Operator reduced to 1D convolutions with Gaussians

  `$$ 
    g(x) = \hat{T}f(x) = \int \alpha e^{-\beta (x-y)^2} f(y) dy
   $$`

- MW representation by scaling projection of the 2D kernel

  `$$ 
    T_{lm}^N = \int \int K(x,y) \phi_l^N(x)\phi_m^N(y) dxdy
   $$`

- `\(l\)` and `\(m\)` are translation indices of nodes
  in the output and input functions, respectively

- MW transform to obtain wavelet terms (2D gives 4 components)

  `$$
    T^{N} = T^{N-1} + C^{N-1} + B^{N-1} + A^{N-1}
   $$`

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Convolution operators
  `$$
    T^{N} = T^{N-1} + C^{N-1} + B^{N-1} + A^{N-1}
   $$`

#### Vanishing moments

<img src="images/vanishing_moments.jpg" style="width: 100%; float: left">


]


---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Convolution operators
  `$$
    T \approx \Bigg(T^{N+1}\Bigg)
   $$`
<img src="images/matrix/mat_1.jpg" style="width: 100%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Convolution operators
  `$$
    T \approx \Bigg(T^{N} + C^{N} + B^{N} + A^{N}\Bigg)
   $$`
<img src="images/matrix/mat_2.jpg" style="width: 100%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Convolution operators
  `$$
    T \approx \Bigg(T^{N}\Bigg) + \Bigg(C^{N} + B^{N} + A^{N}\Bigg)
   $$`
<img src="images/matrix/mat_3.jpg" style="width: 100%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Convolution operators
  `$$
    T \approx
    \Bigg(T^{N-1} + C^{N-1} + B^{N-1} + A^{N-1}\Bigg) +
    \Bigg(C^{N} + B^{N} + A^{N}\Bigg)
   $$`
<img src="images/matrix/mat_4.jpg" style="width: 100%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Convolution operators
  `$$
    T \approx
    \Bigg(T^{N-1}\Bigg) +
    \Bigg(C^{N-1} + B^{N-1} + A^{N-1}\Bigg) +
    \Bigg(C^{N} + B^{N} + A^{N}\Bigg)
   $$`
<img src="images/matrix/mat_5.jpg" style="width: 100%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Convolution operators
  `$$
    T \approx
    T^{N-2} +
    \sum_{n=N-2}^N \Bigg(C^{n} + B^{n} + A^{n}\Bigg)
   $$`
<img src="images/matrix/mat_6.jpg" style="width: 100%; float: left">

]

---

layout: false
.left-column[
## Data structures
### - MWTree
### - MWNode
### - MWOperator
]
.right-column[
#### Convolution operators

- MW operators are 2D trees

- Operator decompositions
  * Gaussian expansion
  * Separated dimension
  * Separated length scales
  * MW decomposition
  `$$
    T \approx T^0 + \sum_{n=0}^{N-1} \Bigg(C^n + B^n + A^n\Bigg)
   $$`

- Linear scaling
  * Vanishing moments
  * Thresholding
  * Bandwidths
]

---
template: inverse
# Algorithms
---

layout: false
.left-column[
## Algorithms
### - Adaptivity
]
.right-column[
- MWTrees are built adaptively

Algorithm

]

---

layout: false
.left-column[
## Algorithms
### - Adaptivity
]
.right-column[
- MWTrees are built adaptively

- calcNode()
  * Projection
  * Addition
  * Multiplication
  * Operator application

- splitCheck()
  * based on wavelet norm

  `$$$
    \|w_l^n\| \geq \epsilon \frac{\|f\|}{2^{-n/2}}
   $$$`

- mwTransform(BottomUp)
  * wavelet decomposition from leaf to root
  * update coarser scaling coefficients
]

---

layout: false
.left-column[
## Algorithms
### - Projection
]
.right-column[
- Perform scaling projection at scale `\(n+1\)`

  `$$$
    s_{jl}^{n+1} = \int f(x)\phi_{jl}^{n+1}(x) dx
    \approx 2^{-(n+1)/2} w_jf(2^{n+1}x_j - l)
   $$$`

- Interpolating property of the basis

- MW transform provides the scaling/wavelet coefficients

  `$$$
    V^{n+1} \rightarrow V^n \oplus W^n
   $$$`
]

---

layout: false
.left-column[
## Algorithms
### - Projection
### - Addition
]
.right-column[
- Sum is fully contained in the same space

  `$$$
    V_k^n + V_K^n \rightarrow V_k^n
   $$$`

- Perform addition node by node

  `$$$
    s_{jl}^{f,n} = s_{jl}^{g,n} + s_{jl}^{h,n} 
    w_{jl}^{f,n} = w_{jl}^{g,n} + w_{jl}^{h,n} 
   $$$`

- Could in principle interpolate from finest refinement level

]

---

layout: false
.left-column[
## Algorithms
### - Projection
### - Addition
### - Multiplication
]
.right-column[
- Product spills over into finer scales

  `$$$
    V_k^n \times V_k^n \rightarrow V_{2k}^n = V_k^n 
    \bigoplus_{m=n}^{\infty} W_k^m
   $$$`

- Perform multiplication node by node at scale `\(n+1\)`

  `$$$
    s_{jl}^{f,(n+1)} = s_{jl}^{g,(n+1)} * s_{jl}^{h,(n+1)} 
   $$$`

- MW transform provides the scaling/wavelet coefficients

  `$$$
    V^{n+1} \rightarrow V^n \oplus W^n
   $$$`

- Adaptive algorithm takes care of the "spill over"
]

---

layout: false
.left-column[
## Algorithms
### - Projection
### - Addition
### - Multiplication
### - Operator application
]
.right-column[
- Operator applied one scale at the time (NS form)

  `$$$
    s_{jl}^{f,n} = \sum_m o_{lm}^{n} * s_{jm}^{f,n} 
   $$$`
]

---

layout: false
.left-column[
## Algorithms
### - Projection
### - Addition
### - Multiplication
### - Operator application
]
.right-column[
- Interpolating property
- cvTransform
- mwTransform
- NS form
- Bandwidths
- Pointer array
- Operator thresholding
- GenNodes
]

---
template: inverse
# Parallelization
---

layout: false
.left-column[
## Parallelization
]
.right-column[
- Tree building algorithm
]

---

name: last-page
template: inverse

Slideshow created using [remark] and served using [cicero]

[remark]: https://github.com/gnab/remark
[cicero]: https://github.com/bast/cicero
